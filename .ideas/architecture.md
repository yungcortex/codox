# DSP Architecture: Codox

**CRITICAL CONTRACT:** This specification is immutable during Stages 1-4 implementation. Stage 1 Planning cannot proceed without this file. Stage 3 (DSP) implements this exact architecture.

**Generated by:** Stage 0 Research (research-planning-agent)
**Generated date:** 2026-01-01
**Referenced by:** Stage 1 (Planning), Stage 3 (DSP Implementation)
**Purpose:** DSP specification defining processing components, signal flow, and JUCE module usage

**Complexity Tier:** 6 (Tier 6: Real-time synthesis with extensive modulation - DEEP research required)

---

## Core Components

### Wavetable Oscillator A

- **JUCE Class:** Custom implementation using `juce::dsp::Oscillator<float>` as reference + wavetable frame interpolation
- **Purpose:** Generate audio from wavetable with morphing and warp modes
- **Parameters Affected:** `osc_a_wavetable`, `osc_a_position`, `osc_a_level`, `osc_a_pan`, `osc_a_octave`, `osc_a_semitone`, `osc_a_fine`, `osc_a_warp_mode`, `osc_a_warp_amount`
- **Configuration:**
  - Wavetable format: 256 frames × 2048 samples per frame (standard Serum format)
  - Frame interpolation: Linear interpolation between adjacent frames based on `position` (0-100%)
  - Pitch calculation: Base MIDI note frequency × octave multiplier (2^octave) × semitone multiplier (2^(semi/12)) × fine multiplier (2^(cents/1200))
  - Warp modes: 5 algorithms (Sync, Bend+, FM, AM, PWM) applied post-wavetable-read
  - Output: Stereo with pan law (constant power panning)

**Algorithm notes:**
- Wavetable reading uses fractional phase accumulation with linear interpolation
- Position parameter (0-100%) maps to frame index (0-255) with linear interpolation between frames
- Phase accumulation: `phase += frequency / sampleRate` per sample
- Warp processing applied to output samples based on `warp_mode` and `warp_amount`

---

### Wavetable Oscillator B

- **JUCE Class:** Custom implementation (identical to Oscillator A)
- **Purpose:** Second independent wavetable oscillator for layering
- **Parameters Affected:** `osc_b_wavetable`, `osc_b_position`, `osc_b_level`, `osc_b_pan`, `osc_b_octave`, `osc_b_semitone`, `osc_b_fine`, `osc_b_warp_mode`, `osc_b_warp_amount`
- **Configuration:** Same as Oscillator A (independent wavetable selection, position, tuning, warp)

---

### Sub Oscillator

- **JUCE Class:** `juce::dsp::Oscillator<float>` with custom waveform callbacks
- **Purpose:** Provide low-frequency foundation (sine, triangle, square waves)
- **Parameters Affected:** `sub_shape`, `sub_octave`, `sub_level`
- **Configuration:**
  - Waveforms: Sine (std::sin), Triangle (custom), Square (custom)
  - Octave range: -2 to 0 (frequency = note_freq × 2^octave)
  - Output: Mono (no pan control)
  - JUCE initializer: `juce::dsp::Oscillator<float>([](float phase) { return std::sin(phase); })` for sine

**Algorithm notes:**
- Triangle wave: `output = (2.0f / juce::MathConstants<float>::pi) * std::asin(std::sin(phase))`
- Square wave: `output = phase < juce::MathConstants<float>::pi ? 1.0f : -1.0f`
- Sub always tracks MIDI note of current voice (no independent tuning)

---

### Noise Oscillator

- **JUCE Class:** Custom implementation using `juce::Random` for generation
- **Purpose:** Generate noise textures (white, pink, digital)
- **Parameters Affected:** `noise_type`, `noise_level`
- **Configuration:**
  - White noise: `juce::Random::getSystemRandom().nextFloat() * 2.0f - 1.0f` (uniform -1 to +1)
  - Pink noise: 1/f filter applied to white noise (Paul Kellet's algorithm)
  - Digital noise: Bit-crushed white noise (sample-and-hold at reduced rate)
  - Output: Stereo (same noise to both channels)

**Algorithm notes (Pink noise):**
```cpp
// Paul Kellet's pink noise filter (7 octaves)
float b0 = 0, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0;
float white = random.nextFloat() * 2.0f - 1.0f;
b0 = 0.99886f * b0 + white * 0.0555179f;
b1 = 0.99332f * b1 + white * 0.0750759f;
// ... (7 stages total)
float pink = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362f;
pink *= 0.11f; // compensation
```

---

### Filter Bank

- **JUCE Class:** Multiple implementations depending on filter type
  - LP/HP/BP/Notch: `juce::dsp::IIR::Filter<float>` with coefficient helpers
  - Ladder filter: `juce::dsp::LadderFilter<float>`
  - Formant filters: Custom implementation (multiple bandpass filters in series)
  - Comb filters: `juce::dsp::DelayLine<float>` with feedback
- **Purpose:** Frequency-selective processing with multiple algorithms
- **Parameters Affected:** `filter_type`, `filter_cutoff`, `filter_resonance`, `filter_drive`, `filter_env_depth`, `filter_keytrack`
- **Configuration:**
  - 5 filter types: LP 24dB, LP 12dB, HP 24dB, BP 12dB, Notch
  - Cutoff range: 20Hz to 20kHz (logarithmic scale)
  - Resonance: 0-100% maps to Q factor (0.5 to 10.0)
  - Drive: Pre-filter gain (0-100% → 1.0x to 10.0x gain)
  - Envelope depth: -100% to +100% modulation of cutoff (bipolar)
  - Keytrack: 0-100% → Cutoff follows MIDI note pitch (0% = fixed, 100% = 1:1 tracking)

**Algorithm notes:**
- LP 24dB: `juce::dsp::IIR::Coefficients<float>::makeLowPass(sampleRate, cutoff, resonance)`
- LP 12dB: Same as LP 24dB but single pole (Q = 0.707 for Butterworth)
- HP 24dB: `juce::dsp::IIR::Coefficients<float>::makeHighPass(sampleRate, cutoff, resonance)`
- Ladder filter (LP Ladder): `juce::dsp::LadderFilter` with resonance 0.0-1.0 mapped from resonance parameter
- Keytrack calculation: `actualCutoff = cutoff * pow(2.0, keytrackAmount * (midiNote - 60) / 12.0)`

---

### Amplitude Envelope (ADSR)

- **JUCE Class:** `juce::ADSR`
- **Purpose:** Shape amplitude over note lifetime
- **Parameters Affected:** `amp_attack`, `amp_decay`, `amp_sustain`, `amp_release`
- **Configuration:**
  - Attack: 0-10s (logarithmic scale)
  - Decay: 0-10s (logarithmic scale)
  - Sustain: 0-100% (linear, final level)
  - Release: 0-10s (logarithmic scale)
  - JUCE parameters: `juce::ADSR::Parameters{attack, decay, sustain, release}`
  - Applied to all oscillators (Osc A, Osc B, Sub, Noise) mixed output

**Algorithm notes:**
- Envelope retriggered on each note-on via `noteOn()` call
- Envelope released on note-off via `noteOff()` call
- Per-voice envelope instance (16 voices × 1 amp envelope each)

---

### Filter Envelope (ADSR)

- **JUCE Class:** `juce::ADSR`
- **Purpose:** Modulate filter cutoff over note lifetime
- **Parameters Affected:** `filt_attack`, `filt_decay`, `filt_sustain`, `filt_release`
- **Configuration:**
  - Attack: 0-10s (logarithmic scale)
  - Decay: 0-10s (logarithmic scale)
  - Sustain: 0-100% (linear, envelope level at sustain phase)
  - Release: 0-10s (logarithmic scale)
  - JUCE parameters: `juce::ADSR::Parameters{attack, decay, sustain, release}`
  - Modulation target: Filter cutoff (controlled by `filter_env_depth` parameter)

**Algorithm notes:**
- Envelope output (0.0-1.0) scaled by `filter_env_depth` (-100% to +100%)
- Modulated cutoff: `cutoff * pow(2.0, envValue * envDepth * 4.0)` (±4 octaves max modulation)
- Per-voice envelope instance (16 voices × 1 filter envelope each)

---

### LFO 1-4

- **JUCE Class:** `juce::dsp::Oscillator<float>` with custom waveform callbacks
- **Purpose:** Low-frequency modulation sources
- **Parameters Affected (per LFO):** `lfo[N]_shape`, `lfo[N]_rate`, `lfo[N]_sync`
- **Configuration:**
  - Shapes: Sine, Triangle, Saw, Square, S&H (Sample & Hold)
  - Rate: 0.01Hz to 100Hz (logarithmic scale, NOT tempo-synced in v1.0)
  - Sync: Boolean (RESERVED for future tempo sync - currently inactive)
  - Output range: -1.0 to +1.0 (bipolar)

**Algorithm notes:**
- Sine: `std::sin(phase)`
- Triangle: `(2.0f / pi) * std::asin(std::sin(phase))`
- Saw: `(phase / (2.0f * pi)) * 2.0f - 1.0f` (ramp up)
- Square: `phase < pi ? 1.0f : -1.0f`
- S&H: Random value held for entire cycle, updated on phase wrap

**NOTE:** LFO modulation routing NOT implemented in v1.0 (no mod matrix in parameter spec). LFOs generate signals but have no destinations. Reserved for future `/improve` addition.

---

### Effects Chain

#### Distortion

- **JUCE Class:** Custom waveshaping algorithm
- **Purpose:** Harmonic saturation
- **Parameters Affected:** `fx_distortion_mix`
- **Configuration:**
  - Algorithm: Hyperbolic tangent `tanh(drive * input)` with drive = 5.0 (fixed)
  - Mix: 0-100% dry/wet blend
  - No drive parameter exposed (fixed moderate saturation in v1.0)

#### Chorus

- **JUCE Class:** `juce::dsp::Chorus<float>`
- **Purpose:** Stereo widening and detuning
- **Parameters Affected:** `fx_chorus_mix`
- **Configuration:**
  - Rate: 0.5 Hz (fixed)
  - Depth: 0.3 (fixed, 30% modulation)
  - Feedback: 0.1 (fixed, subtle feedback)
  - Mix: 0-100% dry/wet blend
  - Centre delay: 7ms (fixed)

#### Phaser

- **JUCE Class:** `juce::dsp::Phaser<float>`
- **Purpose:** Notch filter sweeping effect
- **Parameters Affected:** `fx_phaser_mix`
- **Configuration:**
  - Rate: 0.3 Hz (fixed)
  - Depth: 0.5 (fixed)
  - Feedback: 0.4 (fixed)
  - Mix: 0-100% dry/wet blend
  - Centre frequency: 500 Hz (fixed)

#### Flanger

- **JUCE Class:** Custom implementation using `juce::dsp::DelayLine<float>`
- **Purpose:** Metallic comb filtering effect
- **Parameters Affected:** `fx_flanger_mix`
- **Configuration:**
  - Delay time: 1-10ms modulated by LFO at 0.2 Hz (fixed)
  - Feedback: 0.6 (fixed, pronounced comb filtering)
  - Mix: 0-100% dry/wet blend

#### Delay

- **JUCE Class:** `juce::dsp::DelayLine<float>` (stereo, dual mono)
- **Purpose:** Stereo delay effect
- **Parameters Affected:** `fx_delay_mix`
- **Configuration:**
  - Delay time: 500ms (fixed, NOT tempo-synced in v1.0)
  - Feedback: 0.4 (fixed)
  - Mix: 0-100% dry/wet blend
  - Stereo: Dual mono (left and right independent)

#### Reverb

- **JUCE Class:** `juce::dsp::Reverb`
- **Purpose:** Algorithmic reverb
- **Parameters Affected:** `fx_reverb_mix`
- **Configuration:**
  - Room size: 0.7 (fixed, medium room)
  - Damping: 0.5 (fixed, moderate high-frequency absorption)
  - Width: 1.0 (fixed, full stereo)
  - Mix: 0-100% dry/wet blend

#### EQ

- **JUCE Class:** `juce::dsp::IIR::Filter<float>` (3-band parametric)
- **Purpose:** Frequency balance adjustment
- **Parameters Affected:** `fx_eq_mix`
- **Configuration:**
  - Low shelf: 100 Hz, +3 dB (fixed)
  - Mid peak: 1 kHz, +0 dB (fixed, bypass in v1.0)
  - High shelf: 8 kHz, +2 dB (fixed)
  - Mix: 0-100% dry/wet blend

#### Compressor

- **JUCE Class:** `juce::dsp::Compressor<float>`
- **Purpose:** Dynamic range control
- **Parameters Affected:** `fx_compressor_mix`
- **Configuration:**
  - Threshold: -20 dB (fixed)
  - Ratio: 4:1 (fixed)
  - Attack: 10ms (fixed)
  - Release: 100ms (fixed)
  - Mix: 0-100% dry/wet blend (parallel compression)

**NOTE:** All effects in v1.0 have fixed internal parameters. Only mix amount is exposed. Future `/improve` can expand each effect into full parameter set.

---

## Processing Chain

```
MIDI Input (Note-on/Note-off)
  ↓
Voice Allocation (16 voices, round-robin)
  ↓
Per-Voice Processing (×16):
  ├─ Wavetable Osc A → Level → Pan → [Voice Mix A]
  ├─ Wavetable Osc B → Level → Pan → [Voice Mix B]
  ├─ Sub Oscillator → Level (mono) → [Voice Mix Sub]
  └─ Noise Oscillator → Level → [Voice Mix Noise]
  ↓
Voice Mixer (sum Osc A + Osc B + Sub + Noise)
  ↓
Filter Bank ← Filter Cutoff + (Filter Env × Env Depth) + (Keytrack × Note)
  ↓
Amp Envelope (ADSR) × [Voice Output]
  ↓
Unison Processing (if unison_voices > 1):
  ├─ Duplicate voice ×N
  ├─ Detune each copy by ±(unison_detune × voiceIndex)
  └─ Stereo spread (pan copies across stereo field)
  ↓
Voice Summation (all 16 voices mixed)
  ↓
Effects Chain (serial processing):
  ├─ Distortion (fx_distortion_mix)
  ├─ Chorus (fx_chorus_mix)
  ├─ Phaser (fx_phaser_mix)
  ├─ Flanger (fx_flanger_mix)
  ├─ Delay (fx_delay_mix)
  ├─ Reverb (fx_reverb_mix)
  ├─ EQ (fx_eq_mix)
  └─ Compressor (fx_compressor_mix)
  ↓
Master Volume (master_volume)
  ↓
Stereo Output
```

**Routing notes:**
- Each voice is independent (16 polyphonic voices)
- Oscillators run per-voice (Osc A, Osc B, Sub, Noise)
- Filter runs per-voice (16 filter instances)
- Envelopes run per-voice (16 amp envelopes, 16 filter envelopes)
- LFOs are global (NOT per-voice) - same LFO output for all voices
- Effects chain runs on summed voices (global, NOT per-voice)
- Unison creates virtual voices within each allocated voice
- Glide applies to pitch transitions between consecutive notes (glide_time parameter)

---

## System Architecture

### MIDI Routing

**Input handling:** Omni mode (responds to all MIDI channels)

**Note mapping:**
- All MIDI notes (0-127) trigger synth voices
- Note-on: Allocate voice, start oscillators, trigger envelopes
- Note-off: Release amp envelope (sustain phase → release phase)
- Velocity: Affects initial amp envelope level (0-127 → 0.0-1.0 gain multiplier)

**JUCE classes:**
- `juce::MidiBuffer` - MIDI event storage in processBlock
- `juce::MidiMessage::getNoteNumber()` - Extract note number
- `juce::MidiMessage::getVelocity()` - Extract velocity
- `juce::MidiMessage::isNoteOn()` / `isNoteOff()` - Event type detection

**Processing:**
```cpp
for (const auto metadata : midiMessages)
{
    auto message = metadata.getMessage();
    if (message.isNoteOn())
    {
        int note = message.getNoteNumber();
        float velocity = message.getVelocity() / 127.0f;
        allocateVoice(note, velocity); // Round-robin voice allocation
    }
    else if (message.isNoteOff())
    {
        int note = message.getNoteNumber();
        releaseVoice(note); // Trigger envelope release phase
    }
}
```

**Polyphony:** 16 voices maximum (oldest voice stolen if all busy)

**Monophonic mode:** NOT implemented in v1.0 (all notes polyphonic)

---

### Voice Management

**Voice allocation strategy:** Round-robin with voice stealing
- 16 voice slots (fixed)
- New note-on: Find free voice slot, or steal oldest playing voice
- Voice state: `{ midiNote, velocity, playing, phase, ampEnv, filtEnv }`

**Unison expansion:**
- Each allocated voice spawns `unison_voices` virtual voices (1, 2, 4, 8, or 16)
- Virtual voices are detuned: `detune = ±(unison_detune × voiceIndex / unisonCount)`
- Virtual voices are panned: Spread across stereo field (-1.0 to +1.0)
- CPU cost: Linear with unison count (16 voices × 16 unison = 256 oscillators max)

**Glide/Portamento:**
- Glide time: 0-10s (parameter: `glide_time`)
- Implementation: Exponential pitch smoothing from previous note to current note
- Formula: `currentPitch += (targetPitch - currentPitch) * (1.0 - exp(-1.0 / (glideTime * sampleRate)))`
- Glide mode: Always active when glide_time > 0 (no legato mode in v1.0)

---

### State Persistence

**What state is saved:**
- APVTS parameters: All 47 audio parameters (automatic via APVTS)
- Wavetable selections: `osc_a_wavetable`, `osc_b_wavetable` (integer indices)
- No custom state beyond APVTS (wavetables are built-in, not user-imported in v1.0)

**Serialization format:**
- APVTS: XML via ValueTree (automatic)
- No custom state tree needed

**JUCE classes:**
- `juce::AudioProcessorValueTreeState` - Parameter persistence (automatic)

**Restore behavior:**
- All parameters restored from preset/session via APVTS
- Wavetable indices clipped to valid range (0-3 in v1.0 with 4 built-in wavetables)
- Invalid data: Use defaults (all parameters have default values in parameter-spec.md)

---

## Parameter Mapping

| Parameter ID | Type | Range | DSP Component | Usage |
|-------------|------|-------|---------------|-------|
| master_volume | Float | -60.0 to 6.0 dB | Master Output | Final gain stage (dB to linear: `pow(10.0, dB/20.0)`) |
| osc_a_wavetable | Choice | 0-3 | Wavetable Osc A | Wavetable selection index |
| osc_a_position | Float | 0-100% | Wavetable Osc A | Frame position (0-100% → frame 0-255) |
| osc_a_level | Float | 0-100% | Wavetable Osc A | Output gain (0-100% → 0.0-1.0 linear) |
| osc_a_pan | Float | -100 to +100 | Wavetable Osc A | Stereo pan (constant power law) |
| osc_a_octave | Choice | -4 to +4 | Wavetable Osc A | Octave transpose (freq × 2^octave) |
| osc_a_semitone | Int | -12 to +12 | Wavetable Osc A | Semitone detune (freq × 2^(semi/12)) |
| osc_a_fine | Int | -100 to +100 cents | Wavetable Osc A | Fine detune (freq × 2^(cents/1200)) |
| osc_a_warp_mode | Choice | 0-4 | Wavetable Osc A | Warp algorithm (Sync/Bend+/FM/AM/PWM) |
| osc_a_warp_amount | Float | 0-100% | Wavetable Osc A | Warp intensity (0-100% → algorithm-specific) |
| osc_b_* | (Same) | (Same) | Wavetable Osc B | Same as Osc A (independent) |
| sub_shape | Choice | 0-2 | Sub Oscillator | Waveform (Sine/Triangle/Square) |
| sub_octave | Choice | -2 to 0 | Sub Oscillator | Octave offset (freq × 2^octave) |
| sub_level | Float | 0-100% | Sub Oscillator | Output gain (0-100% → 0.0-1.0 linear) |
| noise_type | Choice | 0-2 | Noise Oscillator | Algorithm (White/Pink/Digital) |
| noise_level | Float | 0-100% | Noise Oscillator | Output gain (0-100% → 0.0-1.0 linear) |
| filter_type | Choice | 0-4 | Filter Bank | Algorithm (LP24/LP12/HP24/BP12/Notch) |
| filter_cutoff | Float | 20-20000 Hz | Filter Bank | Cutoff frequency (logarithmic scale) |
| filter_resonance | Float | 0-100% | Filter Bank | Q factor (0-100% → 0.5-10.0) |
| filter_drive | Float | 0-100% | Filter Bank | Pre-filter gain (0-100% → 1.0-10.0x) |
| filter_env_depth | Float | -100 to +100% | Filter Bank | Envelope modulation depth (bipolar) |
| filter_keytrack | Float | 0-100% | Filter Bank | Keyboard tracking amount (0-100% → 0.0-1.0) |
| amp_attack | Float | 0-10s | Amp Envelope | Attack time (logarithmic scale) |
| amp_decay | Float | 0-10s | Amp Envelope | Decay time (logarithmic scale) |
| amp_sustain | Float | 0-100% | Amp Envelope | Sustain level (0-100% → 0.0-1.0) |
| amp_release | Float | 0-10s | Amp Envelope | Release time (logarithmic scale) |
| filt_attack | Float | 0-10s | Filter Envelope | Attack time (logarithmic scale) |
| filt_decay | Float | 0-10s | Filter Envelope | Decay time (logarithmic scale) |
| filt_sustain | Float | 0-100% | Filter Envelope | Sustain level (0-100% → 0.0-1.0) |
| filt_release | Float | 0-10s | Filter Envelope | Release time (logarithmic scale) |
| lfo1_shape | Choice | 0-4 | LFO 1 | Waveform (Sine/Tri/Saw/Square/S&H) |
| lfo1_rate | Float | 0.01-100 Hz | LFO 1 | Frequency (logarithmic scale) |
| lfo1_sync | Bool | On/Off | LFO 1 | Tempo sync (RESERVED, inactive in v1.0) |
| lfo2_* | (Same) | (Same) | LFO 2 | Same as LFO 1 (independent) |
| lfo3_* | (Same) | (Same) | LFO 3 | Same as LFO 1 (independent) |
| lfo4_* | (Same) | (Same) | LFO 4 | Same as LFO 1 (independent) |
| macro1 | Float | 0-100% | (Unused) | RESERVED for mod matrix (v1.0: no routing) |
| macro2 | Float | 0-100% | (Unused) | RESERVED for mod matrix (v1.0: no routing) |
| macro3 | Float | 0-100% | (Unused) | RESERVED for mod matrix (v1.0: no routing) |
| macro4 | Float | 0-100% | (Unused) | RESERVED for mod matrix (v1.0: no routing) |
| unison_voices | Choice | 0-4 | Voice Manager | Voice count (1/2/4/8/16 mapped from index 0-4) |
| unison_detune | Float | 0-100% | Voice Manager | Detune amount (0-100% → 0.0-0.5 semitones) |
| glide_time | Float | 0-10s | Voice Manager | Portamento time (logarithmic scale) |
| fx_distortion_mix | Float | 0-100% | Distortion FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_chorus_mix | Float | 0-100% | Chorus FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_phaser_mix | Float | 0-100% | Phaser FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_flanger_mix | Float | 0-100% | Flanger FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_delay_mix | Float | 0-100% | Delay FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_reverb_mix | Float | 0-100% | Reverb FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_eq_mix | Float | 0-100% | EQ FX | Dry/wet blend (0-100% → 0.0-1.0) |
| fx_compressor_mix | Float | 0-100% | Compressor FX | Dry/wet blend (0-100% → 0.0-1.0) |

---

## Algorithm Details

### Wavetable Frame Interpolation

**Algorithm:** Linear interpolation between adjacent wavetable frames

**Implementation notes:**
```cpp
// position parameter: 0.0 to 1.0 (from 0-100% parameter)
float frameIndex = position * (numFrames - 1); // e.g., 0-255 for 256 frames
int frame1 = static_cast<int>(frameIndex);
int frame2 = std::min(frame1 + 1, numFrames - 1);
float frac = frameIndex - frame1; // fractional part for interpolation

// For each sample in playback:
float sample1 = wavetable[frame1][phaseIndex]; // Sample from frame1
float sample2 = wavetable[frame2][phaseIndex]; // Sample from frame2
float output = sample1 + frac * (sample2 - sample1); // Linear interpolation
```

- Wavetable format: 256 frames × 2048 samples (each frame is one cycle)
- Phase index: `phaseIndex = static_cast<int>(phase / (2.0 * pi) * 2048) % 2048`
- Phase accumulation: `phase += (2.0 * pi * frequency) / sampleRate`

---

### Warp Modes

**Sync (Hard Sync):**
```cpp
// Reset phase when master oscillator phase wraps
if (masterPhase < lastMasterPhase) {
    slavePhase = 0.0f; // Hard reset
}
// warp_amount controls sync frequency ratio (1.0 to 4.0)
float syncRatio = 1.0f + warpAmount * 3.0f;
```

**Bend+ (Upward Pitch Bend):**
```cpp
// Increase frequency toward end of cycle
float bendFactor = 1.0f + warpAmount * (phase / (2.0 * pi)) * 2.0f;
float bentPhase = phase * bendFactor;
```

**FM (Frequency Modulation from Osc B):**
```cpp
// Modulate Osc A phase with Osc B output
float modDepth = warpAmount * 5.0f; // 0-500% modulation depth
float modSignal = oscB_output; // -1.0 to +1.0
float fmPhase = phase + modDepth * modSignal;
```

**AM (Amplitude Modulation from Osc B):**
```cpp
// Multiply Osc A output with Osc B output
float modDepth = warpAmount; // 0.0 to 1.0
float modSignal = (oscB_output + 1.0f) * 0.5f; // 0.0 to 1.0 (unipolar)
float amOutput = oscA_output * (1.0f - modDepth + modDepth * modSignal);
```

**PWM (Pulse Width Modulation):**
```cpp
// Adjust symmetry of waveform playback
float pulseWidth = 0.5f + warpAmount * 0.4f; // 0.1 to 0.9
float output = phase < (pulseWidth * 2.0 * pi) ? 
               wavetable_sample : -wavetable_sample;
```

---

### Constant Power Panning

**Algorithm:** Equal-power pan law for stereo imaging

**Implementation notes:**
```cpp
// pan parameter: -1.0 (left) to +1.0 (right)
float panAngle = (pan + 1.0f) * 0.25f * pi; // Map to 0 to pi/2
float leftGain = std::cos(panAngle);   // 1.0 at left, 0.0 at right
float rightGain = std::sin(panAngle);  // 0.0 at left, 1.0 at right

leftOutput = monoSignal * leftGain;
rightOutput = monoSignal * rightGain;
```

- Maintains constant perceived loudness across pan range
- Sum of squared gains = 1.0 (energy conservation)
- Center pan (0.0): leftGain = rightGain = 0.707 (-3dB)

---

### Unison Detuning

**Algorithm:** Spread virtual voices with frequency detuning and stereo panning

**Implementation notes:**
```cpp
int unisonCount = unisonVoices; // 1, 2, 4, 8, or 16
float detuneAmount = unisonDetune; // 0.0 to 1.0 (from 0-100% parameter)

for (int i = 0; i < unisonCount; ++i)
{
    // Symmetric detuning around center
    float offset = (i - (unisonCount - 1) * 0.5f) / (unisonCount - 1); // -0.5 to +0.5
    float detuneSemitones = offset * detuneAmount * 0.5f; // ±0.25 semitones max
    float detuneRatio = std::pow(2.0f, detuneSemitones / 12.0f);
    
    // Stereo spread
    float panPosition = offset * 2.0f; // -1.0 to +1.0
    
    // Generate detuned voice
    float detunedFreq = baseFreq * detuneRatio;
    // ... (oscillator processing with detunedFreq)
}
```

- CPU cost: Linear with unison count (16 voices × 16 unison = 256 oscillators)
- Detuning creates chorusing/widening effect
- Stereo spread prevents phase cancellation

---

## Integration Points

### Feature Dependencies

- **Oscillators → Filter:** All oscillator outputs are summed BEFORE filtering
  - Filter processes mixed oscillator signal (not individual oscillators)
  - Reason: Computational efficiency (16 voices × 1 filter vs 16 voices × 4 oscillators × 1 filter)

- **Filter Envelope → Filter Cutoff:** Envelope modulates cutoff frequency
  - Filter envelope generates 0.0-1.0 value
  - Scaled by `filter_env_depth` parameter (-100% to +100%)
  - Applied as exponential cutoff modulation (±4 octaves)

- **Amp Envelope → Voice Output:** Envelope shapes final voice amplitude
  - Applied AFTER filter (standard subtractive synthesis order)
  - Reason: Envelope controls perceived loudness, not just filter input

- **Unison → Voice Count:** Unison expands allocated voices into virtual voices
  - Each voice spawns `unison_voices` virtual voices (1-16)
  - Virtual voices processed in parallel (same oscillator parameters, different detune/pan)

- **Effects Chain → Voice Summation:** Effects process summed voice output
  - Effects are NOT per-voice (would be 16× CPU cost)
  - All voices mixed BEFORE effects chain

---

### Parameter Interactions

- **Unison Voices × Unison Detune:** Combined CPU impact
  - 16 allocated voices × 16 unison = 256 oscillators maximum
  - Each oscillator: 2 wavetable reads + 1 sub + 1 noise = 4 generators
  - Peak CPU: 256 × 4 = 1024 audio generators (extremely high)
  - Mitigation: Warn users about CPU usage at high unison counts

- **Filter Cutoff × Filter Env Depth × Filter Keytrack:** Triple interaction
  - Base cutoff: `filter_cutoff` parameter (20Hz-20kHz)
  - Envelope modulation: `cutoff × pow(2.0, envValue × envDepth × 4.0)`
  - Keytrack modulation: `cutoff × pow(2.0, keytrackAmount × (note - 60) / 12.0)`
  - Final cutoff: `baseCutoff × envMod × keytrackMod` (all three multiply)
  - Risk: Extreme values can push cutoff above Nyquist (sampleRate/2) → clamp to Nyquist

- **LFOs generate signals but NO destinations in v1.0:**
  - LFO parameters are functional (shape, rate, sync)
  - LFO output is calculated but not routed anywhere
  - Reason: No mod matrix implemented in parameter spec
  - Future: `/improve` can add mod matrix (LFO → Filter Cutoff, LFO → Osc Pitch, etc.)

- **Macros have NO function in v1.0:**
  - Macro parameters exist in APVTS (macro1-4)
  - No routing to any DSP components
  - Reason: Mod matrix required for macro functionality
  - Future: `/improve` can add mod matrix (Macro → multiple destinations)

---

### Processing Order Requirements

**Sequential processing order (REQUIRED per voice):**

1. **Generate MIDI-triggered note parameters:**
   - Extract MIDI note number → Base frequency calculation
   - Extract velocity → Amplitude scaling factor
   - Trigger amp envelope and filter envelope (noteOn)

2. **Generate oscillator outputs:**
   - Wavetable Osc A: Calculate frequency (octave/semi/fine), read wavetable, apply warp
   - Wavetable Osc B: Calculate frequency (octave/semi/fine), read wavetable, apply warp
   - Sub Oscillator: Calculate frequency (sub_octave), generate waveform (sub_shape)
   - Noise Oscillator: Generate noise sample (noise_type)

3. **Mix oscillators:**
   - Sum: `(OscA × level × pan) + (OscB × level × pan) + (Sub × level) + (Noise × level)`
   - Apply pan to Osc A and Osc B (stereo)
   - Sub and Noise are mono (centered)

4. **Process filter:**
   - Calculate modulated cutoff: Base cutoff × envelope mod × keytrack mod
   - Clamp cutoff to valid range (20 Hz to Nyquist)
   - Apply filter to mixed oscillator signal

5. **Apply amp envelope:**
   - Multiply filtered signal by amp envelope value (0.0-1.0)
   - Envelope state: Attack → Decay → Sustain (held) → Release (on note-off)

6. **Expand unison voices (if unison_voices > 1):**
   - Duplicate voice output `unison_voices` times
   - Apply detune to each virtual voice (recalculate oscillators with detuned freq)
   - Apply stereo spread (pan virtual voices across field)
   - Sum all virtual voices

**Why order matters:**
- **Oscillators before filter:** Standard subtractive synthesis (generate harmonics, then filter)
- **Filter before amp envelope:** Envelope controls perceived loudness (post-filtering)
- **Unison after per-voice processing:** Virtual voices share same oscillator parameters (only detune/pan differ)
- **Voice summation before effects:** Effects are global (not per-voice) for CPU efficiency

**Global processing order (post-voice-summation):**

1. **Sum all voices:** 16 polyphonic voices mixed to stereo
2. **Effects chain (serial):** Distortion → Chorus → Phaser → Flanger → Delay → Reverb → EQ → Compressor
3. **Master volume:** Final gain stage (dB to linear conversion)
4. **Output:** Stereo output to DAW

**Why serial effects:**
- Predictable signal flow (each effect processes previous effect's output)
- Standard plugin architecture (matches Serum, Vital, etc.)
- No parallel routing in v1.0 (future enhancement)

---

### Thread Boundaries

**Audio thread:**
- All DSP processing (oscillators, filters, envelopes, effects, voice management)
- MIDI message processing (note-on/note-off, voice allocation)
- Parameter reads via `APVTS::getRawParameterValue()->load()` (atomic)
- Voice state updates (phase accumulation, envelope progression)
- Sample-by-sample processing in processBlock()

**Message thread:**
- Parameter updates from UI via APVTS (atomic writes)
- Preset loading/saving (APVTS handles serialization)
- UI repaints (WebView updates)
- Randomization trigger (updates all parameters atomically via APVTS)

**No background thread needed:**
- No file I/O (wavetables are built-in, embedded in binary)
- No folder scanning
- All processing is real-time compatible

**Communication:**
- APVTS parameters: Atomic reads (audio thread) / atomic writes (message thread)
- No custom thread communication needed (APVTS handles it)
- No locks in audio thread (all operations are lock-free or wait-free)

**Safety guarantees:**
- Audio thread NEVER allocates memory (all buffers pre-allocated in prepareToPlay)
- Audio thread NEVER waits on locks (all parameter access is atomic)
- Voice allocation uses pre-allocated voice array (no dynamic allocation)

---

## Implementation Risks

### Wavetable Engine

**Complexity:** HIGH
- Requires custom wavetable reader with frame interpolation
- Wavetable loading and memory management
- Phase accumulation and wrapping
- Warp mode algorithms (5 different algorithms)

**Risk Level:** MEDIUM

**Risk factors:**
1. Custom wavetable format: 256 frames × 2048 samples = 512KB per wavetable (large memory footprint)
2. Frame interpolation artifacts if done incorrectly (zipper noise, pops)
3. Phase accumulation overflow (must wrap correctly to avoid discontinuities)
4. Warp modes have different algorithms (Sync, FM, AM require cross-oscillator communication)

**Alternative approaches:**
1. **Use juce::dsp::Oscillator with single waveform (no wavetables):**
   - Complexity: LOW
   - Quality: Much lower (no wavetable morphing, just basic waveforms)
   - Best for: Prototyping to validate voice management and envelope architecture

2. **Use pre-rendered wavetable samples (no real-time interpolation):**
   - Complexity: MEDIUM
   - Quality: Lower (no smooth morphing, stepped transitions)
   - CPU: Lower (~50% of interpolated approach)
   - Best for: If frame interpolation proves too CPU-intensive

**Fallback architecture:**
- **Primary:** Full wavetable engine with frame interpolation and warp modes
- **Fallback 1:** If warp modes too complex → Basic wavetable without warp (position morphing only)
- **Fallback 2:** If frame interpolation artifacts → Pre-rendered wavetable positions (no interpolation)
- **Fallback 3:** If wavetable proves too complex → Standard oscillator with basic waveforms (sine, saw, square)

**Mitigation strategy:**
1. Research open-source wavetable implementations (Surge, Vital - both open-source wavetable synths)
2. Implement basic wavetable reader first (no warp, no frame interpolation) to validate architecture
3. Add frame interpolation as Phase 2 (test for artifacts)
4. Add warp modes one-by-one as Phase 3 (test each independently)
5. Benchmark CPU usage early (may need quality settings or frame count reduction)

---

### Voice Management (16 Polyphonic Voices)

**Complexity:** MEDIUM
- Voice allocation and stealing logic
- Per-voice state management (note, velocity, envelopes, oscillators)
- 16 voices × 4 oscillators × 2 envelopes = 128 active components

**Risk Level:** LOW

**Risk factors:**
1. Voice stealing can cause clicks if not handled smoothly (need envelope fade-out)
2. High polyphony (16 voices) can cause CPU spikes if all voices active
3. Per-voice filter state must be isolated (no shared state between voices)

**Alternative approaches:**
1. **Reduce polyphony to 8 voices:**
   - Complexity: Same
   - CPU: 50% reduction
   - Best for: If 16 voices prove too CPU-intensive

2. **Dynamic polyphony (user-adjustable):**
   - Complexity: Same
   - Benefit: User controls CPU vs. polyphony tradeoff
   - Implementation: Add polyphony parameter (not in spec - requires `/improve`)

**Fallback architecture:**
- **Primary:** 16 voices with round-robin allocation and voice stealing
- **Fallback 1:** If CPU too high → 8 voices (reduce polyphony)
- **Fallback 2:** If voice stealing causes clicks → Implement fade-out envelope on stolen voices

**Mitigation strategy:**
1. Check `juce8-critical-patterns.md` for synth bus configuration (IS_SYNTH flag required)
2. Implement voice class with clear state encapsulation (Voice struct with all per-voice data)
3. Use array of Voice structs (not dynamic allocation) - pre-allocate in prepareToPlay
4. Benchmark CPU with all 16 voices active + 16 unison (worst case = 256 oscillators)

---

### Unison Processing (Up to 16 Virtual Voices per Voice)

**Complexity:** HIGH
- 16 allocated voices × 16 unison = 256 oscillators maximum
- Detuning and stereo spread calculations per virtual voice
- Exponential CPU scaling with unison count

**Risk Level:** MEDIUM

**Risk factors:**
1. Extreme CPU usage at max settings (16 voices × 16 unison × 4 oscillators = 1024 generators)
2. Detuning calculation must be sample-accurate (no parameter smoothing artifacts)
3. Stereo spread can cause phase cancellation if not implemented correctly

**Alternative approaches:**
1. **Reduce max unison to 8 voices:**
   - Complexity: Same
   - CPU: 50% reduction
   - Quality: Still produces lush unison effect
   - Best for: If 16 unison proves too CPU-intensive

2. **Unison on Osc A only (not Osc B, Sub, Noise):**
   - Complexity: Lower (fewer oscillators to expand)
   - CPU: ~40% reduction (Osc A is typically the primary oscillator)
   - Quality: Slightly lower (less lush)

**Fallback architecture:**
- **Primary:** 16 unison voices per allocated voice (all oscillators)
- **Fallback 1:** If CPU too high → 8 unison voices max
- **Fallback 2:** If still too high → Unison on Osc A only (not Osc B/Sub/Noise)
- **Fallback 3:** If extreme CPU → Unison disabled (1 voice per note)

**Mitigation strategy:**
1. Implement unison as last feature (after oscillators, filters, envelopes working)
2. Benchmark CPU incrementally (test 2, 4, 8, 16 unison separately)
3. Add CPU usage warning in UI if unison > 8 (inform users of performance impact)
4. Consider quality settings (Low/Medium/High unison counts)

---

### Effects Chain (8 Effects Serial Processing)

**Complexity:** MEDIUM
- 8 effects in series (order matters)
- Each effect has dry/wet mix parameter
- Fixed internal parameters (no deep editing in v1.0)

**Risk Level:** LOW

**Risk factors:**
1. Serial effects can accumulate latency (delay + reverb = combined latency)
2. Compressor at end of chain can cause pumping if not tuned correctly
3. Fixed parameters may not suit all use cases (no tweaking in v1.0)

**Alternative approaches:**
1. **Reduce effects count to 4 (Distortion, Delay, Reverb, Compressor):**
   - Complexity: Lower (fewer effects to implement)
   - Quality: Core effects covered (chorus/phaser/flanger are "nice to have")
   - Best for: If 8 effects prove too time-consuming

2. **Parallel effects bus (not serial chain):**
   - Complexity: HIGHER (requires routing matrix)
   - Quality: More flexible (can blend effects independently)
   - Best for: Future enhancement via `/improve`

**Fallback architecture:**
- **Primary:** 8 effects serial chain with fixed parameters
- **Fallback 1:** If 8 effects too much → 4 core effects (Distortion, Delay, Reverb, Compressor)
- **Fallback 2:** If effects cause latency issues → Reduce to 2 effects (Delay, Reverb)

**Mitigation strategy:**
1. Implement effects one-by-one (test each in isolation before adding to chain)
2. Use JUCE built-in effects where possible (juce::dsp::Chorus, juce::dsp::Phaser, etc.)
3. Test latency reporting (getLatencySamples) with all effects active
4. Document fixed parameters in user manual (users know what to expect in v1.0)

---

### Overall Project Risk

**Overall complexity:** VERY HIGH (Score: 9.2 / 10)
- Wavetable engine (HIGH) + 16-voice polyphony (MEDIUM) + 16 unison (HIGH) + 8 effects (MEDIUM)
- 50 parameters (highest in system so far)
- 4 major subsystems (oscillators, filters/envelopes, voice management, effects)

**Highest risk component:** Wavetable Engine + Unison Processing (tied)
- Wavetable: ~40% of project risk (custom implementation, frame interpolation, warp modes)
- Unison: ~40% of project risk (extreme CPU scaling, 256 oscillators max)
- Combined: ~80% of total project risk

**Recommended approach:**
1. **Phase 1 - Validate core architecture (LOW risk):**
   - Basic sine oscillator (no wavetable) + simple LP filter + amp envelope
   - Goal: Verify voice management, MIDI routing, IS_SYNTH flag
   - Duration: ~2 hours

2. **Phase 2 - Build wavetable foundation (MEDIUM risk):**
   - Implement single wavetable (no morphing) with phase accumulation
   - Test for audio artifacts (clicks, pops, discontinuities)
   - Duration: ~4 hours

3. **Phase 3 - Add frame interpolation (MEDIUM-HIGH risk):**
   - Linear interpolation between frames based on position parameter
   - Test for zipper noise and morphing smoothness
   - Duration: ~3 hours

4. **Phase 4 - Implement warp modes (HIGH risk):**
   - Add warp modes one-by-one (Sync, Bend+, FM, AM, PWM)
   - Test each for artifacts and CPU usage
   - Duration: ~6 hours (1hr per warp mode + testing)

5. **Phase 5 - Add second oscillator and mixer (LOW risk):**
   - Duplicate Osc A as Osc B (code reuse)
   - Add Sub and Noise oscillators (simple waveforms)
   - Test oscillator mixing and panning
   - Duration: ~2 hours

6. **Phase 6 - Implement filter bank (MEDIUM risk):**
   - Add 5 filter types (LP24, LP12, HP24, BP12, Notch)
   - Implement filter envelope and keytrack
   - Duration: ~3 hours

7. **Phase 7 - Add unison processing (HIGH risk):**
   - Start with 2 unison, test, then 4, 8, 16 incrementally
   - Benchmark CPU at each step
   - Implement fallback if CPU too high
   - Duration: ~4 hours

8. **Phase 8 - Implement effects chain (MEDIUM risk):**
   - Add effects one-by-one (Distortion → Chorus → ... → Compressor)
   - Test serial routing and latency
   - Duration: ~5 hours (8 effects × ~30min each + testing)

9. **Phase 9 - Add LFOs (LOW risk but NO ROUTING):**
   - Implement LFO generation (shape, rate)
   - NOTE: LFOs generate signals but NOT routed (no mod matrix)
   - Duration: ~1 hour

10. **Phase 10 - Polish and optimize (LOW risk):**
    - CPU profiling and optimization
    - Denormal protection
    - Parameter smoothing
    - Duration: ~2 hours

**Total estimated duration:** ~32 hours (phased implementation critical)

**Critical success factors:**
- Incremental testing at each phase (catch artifacts early)
- CPU benchmarking throughout (know when to fall back)
- Reference implementations (Surge, Vital for wavetable code patterns)
- Fallback architectures ready (documented alternatives for each high-risk component)

---

## Architecture Decisions

### Wavetable Format: 256 Frames × 2048 Samples

**Decision:** Use Serum-compatible wavetable format (256 frames, 2048 samples per frame)

**Rationale:**
- Industry standard format (Serum, Vital, Phase Plant all use this format)
- 256 frames provides smooth morphing (1 frame per ~0.4% position change)
- 2048 samples per frame provides high harmonic resolution (up to 1024 harmonics)
- Enables future wavetable import feature (users can import Serum wavetables)

**Alternatives considered:**
1. **64 frames × 1024 samples:**
   - Why rejected: Less smooth morphing (visible stepping), lower harmonic resolution
   - CPU benefit: ~4× less memory (128KB vs 512KB per wavetable)
   - When to reconsider: If memory footprint becomes issue

2. **512 frames × 2048 samples:**
   - Why rejected: Double memory (1MB per wavetable), no perceptual benefit
   - Quality benefit: Ultra-smooth morphing (may be overkill)
   - When to reconsider: If morphing artifacts appear with 256 frames

**Tradeoffs accepted:**
- **Large memory footprint:** 512KB per wavetable × 4 wavetables = 2MB (acceptable for modern systems)
- **Frame interpolation CPU cost:** Linear interpolation adds ~10% CPU vs. no interpolation
  - Acceptable because: Smooth morphing is core feature, CPU cost is predictable

**When to revisit:**
- If memory usage becomes issue (reduce to 64 frames)
- If CPU usage too high (pre-render wavetable positions, no interpolation)
- If morphing artifacts appear (increase to 512 frames or improve interpolation)

---

### V1.0 Scope Reduction: No Mod Matrix

**Decision:** Omit modulation matrix in v1.0 (LFOs and Macros exist but have no routing)

**Rationale:**
- Parameter spec does NOT include mod matrix parameters (no source/destination/depth parameters)
- Creative brief mentions mod matrix as feature goal, but parameter spec is immutable contract
- LFO and Macro parameters are present (shape, rate, sync, values) but no routing mechanism
- Implementing mod matrix without parameter backing would violate contract immutability

**Alternatives considered:**
1. **Add mod matrix parameters to parameter spec:**
   - Why rejected: Parameter spec is finalized and immutable (contract violation to modify)
   - Would require: Going back to Stage 0 (ideation) to revise contracts

2. **Implement hidden mod matrix (hardcoded routings):**
   - Why rejected: Not user-controllable, defeats purpose of mod matrix
   - Violates principle: DSP should reflect parameter spec exactly

**Tradeoffs accepted:**
- **Reduced functionality in v1.0:** LFOs and Macros generate signals but don't modulate anything
  - Acceptable because: Can be added via `/improve` in v1.1 (additive enhancement, no breaking changes)
- **Creative brief mismatch:** Brief mentions mod matrix, but spec doesn't support it
  - Acceptable because: Parameter spec is source of truth (later in workflow, more authoritative)

**Future enhancement path:**
- Run `/improve Codox` to add mod matrix in v1.1
- New parameters: mod_source_1-8, mod_dest_1-8, mod_depth_1-8 (24 new parameters)
- Backward compatible: Existing presets load with mod matrix disabled (default values)

**When to revisit:**
- If users request mod matrix in feedback (high priority for `/improve`)
- If LFOs/Macros feel incomplete without routing (revisit scope vs. contract)

---

### Effects: Fixed Parameters in V1.0

**Decision:** Implement 8 effects with fixed internal parameters (only mix exposed)

**Rationale:**
- Parameter spec includes 8 `fx_*_mix` parameters (dry/wet blend only)
- No parameters for effect-specific controls (delay time, reverb size, chorus rate, etc.)
- Reduces complexity for v1.0 (8 parameters instead of ~40 for full effect controls)
- Fixed parameters can be tuned to "musical" defaults (tested and balanced)

**Alternatives considered:**
1. **Implement full effect parameter sets:**
   - Why rejected: Parameter spec doesn't include these parameters (contract violation)
   - Would add: ~40 additional parameters (5 params × 8 effects average)

2. **Reduce effects count to 4 (only core effects):**
   - Why rejected: Parameter spec explicitly lists 8 effects (all must be implemented)
   - Removing effects would violate parameter spec contract

**Tradeoffs accepted:**
- **Limited tweak-ability:** Users can't adjust delay time, reverb size, chorus rate, etc.
  - Acceptable because: Fixed parameters are tuned to versatile defaults (cover 80% of use cases)
- **Less flexibility than Serum:** Serum allows deep effect editing
  - Acceptable because: v1.0 focuses on core synthesis (effects are secondary), can expand via `/improve`

**Fixed parameter values (chosen for musicality):**
- **Distortion:** Drive = 5.0 (moderate saturation, not extreme)
- **Chorus:** Rate = 0.5Hz, Depth = 0.3, Delay = 7ms (lush stereo widening)
- **Phaser:** Rate = 0.3Hz, Depth = 0.5, Feedback = 0.4 (subtle sweeping)
- **Flanger:** Rate = 0.2Hz, Delay = 1-10ms, Feedback = 0.6 (pronounced comb filtering)
- **Delay:** Time = 500ms, Feedback = 0.4 (rhythmic echo without runaway)
- **Reverb:** Size = 0.7, Damping = 0.5 (medium room, balanced brightness)
- **EQ:** Low = +3dB@100Hz, High = +2dB@8kHz (gentle low/high boost)
- **Compressor:** Threshold = -20dB, Ratio = 4:1, Attack = 10ms, Release = 100ms (transparent dynamics)

**Future enhancement path:**
- Run `/improve Codox` to expand each effect with full parameter set
- Example: Delay v1.1 adds `fx_delay_time`, `fx_delay_feedback`, `fx_delay_sync`
- Backward compatible: v1.0 presets load with new parameters at default values (matching v1.0 fixed values)

**When to revisit:**
- If users request effect tweaking (prioritize which effects to expand first)
- If fixed parameters don't cover common use cases (retune defaults or add parameters)

---

### Polyphony: 16 Voices Fixed

**Decision:** Implement 16 polyphonic voices (not user-adjustable in v1.0)

**Rationale:**
- Standard for professional synths (Serum = 16, Vital = 16, Massive = 16)
- Balances CPU usage vs. expressive playing (16 notes simultaneous = full chords + sustain)
- No polyphony parameter in parameter spec (fixed implementation)

**Alternatives considered:**
1. **8 voices (reduce polyphony):**
   - Why rejected: Feels limited for complex chords or sustained pads
   - CPU benefit: 50% reduction

2. **32 voices (increase polyphony):**
   - Why rejected: Doubles CPU for minimal musical benefit (rare to use >16 notes)
   - When to reconsider: If users report voice stealing during performance

3. **User-adjustable polyphony (parameter):**
   - Why rejected: No polyphony parameter in spec (would require contract change)
   - When to reconsider: Future `/improve` can add polyphony setting

**Tradeoffs accepted:**
- **Fixed CPU scaling:** 16 voices always allocated (even if only 1 note playing)
  - Mitigation: Voice deactivation when not in use (skip processing for silent voices)
- **Voice stealing:** If >16 notes pressed, oldest voice is stolen
  - Acceptable because: 16 notes exceeds typical musical use (full 4-note chords + sustain)

**When to revisit:**
- If CPU profiling shows 16 voices too expensive (reduce to 8)
- If users report frequent voice stealing (increase to 32 or add dynamic polyphony)

---

## Special Considerations

### Thread Safety

- All parameter reads use atomic `getRawParameterValue()->load()` (APVTS provides atomic access)
- Voice state is per-voice (no shared state between voices) - each voice has own oscillator phases, envelopes
- LFO phase state is global but read-only from audio thread (no race conditions)
- Filter coefficient updates happen in audio thread based on parameter values (no allocations, no locks)
- Wavetable data is read-only after prepareToPlay (no thread conflicts)

**Example:**
```cpp
// Audio thread parameter access (atomic read)
float cutoff = *apvts.getRawParameterValue("filter_cutoff");
float resonance = *apvts.getRawParameterValue("filter_resonance");

// Per-voice state (no shared memory)
for (int v = 0; v < numVoices; ++v) {
    voices[v].oscA_phase += voices[v].oscA_freq / sampleRate; // Independent
    voices[v].ampEnv.getNextSample(); // Per-voice envelope
}
```

---

### Performance

**Estimated CPU usage per component:**
- **Wavetable Oscillator A:** ~8% CPU (frame interpolation + phase accumulation)
- **Wavetable Oscillator B:** ~8% CPU (same as Osc A)
- **Sub Oscillator:** ~2% CPU (simple waveform generation)
- **Noise Oscillator:** ~1% CPU (random number generation + pink filter)
- **Filter Bank:** ~10% CPU per voice (IIR processing + coefficient calculation)
- **Amp Envelope:** ~1% CPU per voice (ADSR state machine)
- **Filter Envelope:** ~1% CPU per voice (ADSR state machine)
- **Unison Processing:** ~15% CPU per unison voice (detuning + stereo spread)
- **Effects Chain:** ~25% CPU total (reverb ~15%, delay ~5%, others ~5%)

**Total estimated CPU (worst case):**
- 16 voices × 16 unison × (Osc A + Osc B + Sub + Noise + Filter + Envelopes) = ~800% CPU (8 cores)
- Realistic usage: 4 voices × 4 unison × components + effects = ~120% CPU (1.2 cores)
- Conservative estimate: Expect ~80-150% single core usage for typical patches

**Hot paths and optimization opportunities:**
- Wavetable frame interpolation (inner loop, per-sample) - Consider SIMD optimization
- Filter processing (per-voice, per-sample) - Pre-calculate coefficients once per buffer, not per-sample
- Unison detuning (multiplicative CPU scaling) - Add quality settings (Low/Medium/High unison counts)
- Voice deactivation (skip silent voices) - Check amp envelope state, skip processing if envelope = 0.0

**Buffer size sensitivity:**
- Smaller buffers (64 samples) = higher CPU (more frequent processBlock calls)
- Larger buffers (512 samples) = lower CPU but higher latency
- Target: Stable at 256 samples (typical DAW buffer size)

---

### Denormal Protection

- Use `juce::ScopedNoDenormals` in `processBlock()` to disable denormal processing (flush-to-zero)
- All JUCE DSP components handle denormals internally (juce::dsp::Filter, juce::dsp::Reverb, etc.)
- Custom oscillators use phase wrapping to avoid denormals (phase always in range 0 to 2π)
- Filter feedback paths include denormal protection (add small epsilon to prevent denormal oscillation)

**Example:**
```cpp
void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages) override
{
    juce::ScopedNoDenormals noDenormals; // Flush-to-zero mode
    
    // ... (processing code)
}
```

---

### Sample Rate Handling

- All DSP components reinitialized in `prepareToPlay()` with new sample rate
- Wavetable phase increment: `(2π × frequency) / sampleRate` (recalculated per sample)
- Filter coefficients: Recalculated when sample rate changes (cutoff in Hz, resonance dimensionless)
- Envelope times: `juce::ADSR` handles sample rate internally (time in seconds → samples)
- LFO phase increment: `(2π × rate) / sampleRate` (recalculated on sample rate change)
- Effects (reverb, delay): Reinitialized in `prepareToPlay()` (buffer sizes recalculated)

**Example:**
```cpp
void prepareToPlay(double sampleRate, int samplesPerBlock) override
{
    currentSampleRate = sampleRate;
    
    // Reinitialize all components
    for (int v = 0; v < numVoices; ++v) {
        voices[v].ampEnv.setSampleRate(sampleRate);
        voices[v].filtEnv.setSampleRate(sampleRate);
        voices[v].filter.prepare({ sampleRate, (uint32)samplesPerBlock, 2 });
    }
    
    // Effects
    reverb.prepare({ sampleRate, (uint32)samplesPerBlock, 2 });
    delay.prepare({ sampleRate, (uint32)samplesPerBlock, 2 });
    // ... (other effects)
}
```

---

### Latency

**Processing latency sources:**
- Wavetable oscillators: Minimal (~1 sample phase interpolation)
- Filters: Minimal (IIR filters have <1 sample group delay)
- Effects:
  - Delay: 500ms (user-perceived latency, part of effect)
  - Reverb: ~20-50ms internal algorithmic latency
  - Chorus/Phaser/Flanger: ~5-10ms delay line latency
- Total plugin latency: ~70-80ms (primarily from reverb and delay effects)

**Host compensation:**
- Report latency via `getLatencySamples()` for host compensation
- Calculation: Sum of all effect latencies (reverb + chorus + phaser + flanger)
- Delay effect NOT included (user-intended latency, not plugin-induced)

**Example:**
```cpp
int getLatencySamples() const override
{
    int latency = 0;
    latency += reverb.getLatencySamples(); // ~40ms at 48kHz
    latency += chorus.getLatencySamples(); // ~7ms
    latency += phaser.getLatencySamples(); // ~5ms
    latency += flanger.getLatencySamples(); // ~5ms
    return latency; // Total: ~57ms = 2736 samples at 48kHz
}
```

---

## Research References

### Professional Plugins

1. **Serum (Xfer Records)**
   - Industry-leading wavetable synth (primary reference for Codox)
   - Wavetable format: 256 frames × 2048 samples (Codox matches this)
   - Warp modes: Sync, Bend, FM, AM, PWM, etc. (Codox implements subset)
   - Observed: Extensive mod matrix (LFO → any parameter) - NOT in Codox v1.0
   - Effects rack: 10 effects with deep editing - Codox v1.0 has fixed parameters
   - Unison: Up to 16 voices with detune and stereo spread (Codox matches)
   - CPU usage: ~30-60% single core for typical patch (Codox target: similar)

2. **Vital (Matt Tytel - Open Source)**
   - Modern wavetable synth with Serum-like feature set
   - Wavetable format: Same as Serum (256 × 2048)
   - Open-source: Excellent reference for wavetable implementation code
   - Observed: Very efficient wavetable interpolation (SIMD optimized) - Consider for Codox optimization
   - Mod matrix: Visual drag-and-drop routing (inspiration for future Codox `/improve`)
   - Effects: Distortion, Chorus, Phaser, Flanger, Delay, Reverb, EQ, Compressor (Codox matches list)

3. **Phase Plant (Kilohearts)**
   - Modular wavetable synth (different architecture than Codox)
   - Observed: Extensive modulation routing, snap-in effects
   - Wavetable morphing: Smooth frame interpolation (validates Codox approach)
   - CPU: Higher than Serum due to modular architecture (Codox simpler = lower CPU)

4. **Pigments (Arturia)**
   - Hybrid synth (wavetable + granular + virtual analog)
   - Wavetable engine: 256 frames, smooth morphing (same as Codox)
   - Observed: Extensive built-in wavetable library (~400 wavetables) - Codox v1.0 has 4
   - Effects: Deep parameter control - Codox v1.0 simpler (fixed params)

**Key takeaways:**
- 256 × 2048 wavetable format is industry standard (Codox correct choice)
- Frame interpolation is essential for smooth morphing (linear interpolation sufficient)
- Unison up to 16 voices is competitive (Codox matches)
- Mod matrix is expected feature BUT can be v1.1 enhancement (not blocking for v1.0)
- Effects with fixed parameters are acceptable for v1.0 (Vital also started simple)

---

### JUCE Documentation

**Core audio classes:**
- `juce::dsp::Oscillator<float>` - Base oscillator template (reference for custom wavetable oscillator)
  - Used for Sub oscillator and LFOs (standard waveforms)
  - NOT used for wavetable oscillators (custom implementation required)
- `juce::ADSR` - Envelope generator with Attack/Decay/Sustain/Release
  - Used for amp envelope and filter envelope (per-voice instances)
  - Handles sample rate internally, provides `noteOn()` / `noteOff()` / `getNextSample()` API
- `juce::dsp::IIR::Filter<float>` - Biquad IIR filter
  - Used for LP, HP, BP, Notch filters
  - Coefficient helpers: `makeLowPass()`, `makeHighPass()`, `makeBandPass()`, `makeNotch()`
- `juce::dsp::LadderFilter<float>` - Moog-style ladder filter
  - Used for LP Ladder filter type
  - Resonance control (0.0-1.0 range)

**Effects classes:**
- `juce::dsp::Reverb` - Algorithmic reverb (Freeverb-based)
  - Parameters: roomSize, damping, wetLevel, dryLevel, width, freezeMode
- `juce::dsp::Chorus<float>` - Chorus effect
  - Parameters: rate, depth, centreDelay, feedback, mix
- `juce::dsp::Phaser<float>` - Phaser effect
  - Parameters: rate, depth, centreFrequency, feedback, mix
- `juce::dsp::DelayLine<float>` - Delay line with interpolation
  - Used for Delay effect and Flanger effect
  - Interpolation types: None, Linear, Lagrange3rd (Codox uses Linear for simplicity)
- `juce::dsp::Compressor<float>` - Dynamics compressor
  - Parameters: threshold, ratio, attack, release

**Processing infrastructure:**
- `juce::dsp::ProcessSpec` - DSP component configuration (sampleRate, blockSize, numChannels)
  - Used in `prepare()` calls for all juce::dsp components
- `juce::dsp::AudioBlock<float>` - Non-owning view of audio buffer
  - Used for juce::dsp processing (modern JUCE 8 API)
- `juce::dsp::ProcessContextReplacing<float>` - Processing context for in-place processing
  - Pattern: `AudioBlock → ProcessContext → component.process(context)`

**MIDI classes:**
- `juce::MidiBuffer` - Container for MIDI events
  - Iterated in `processBlock()` to extract note-on/note-off messages
- `juce::MidiMessage` - Individual MIDI message
  - Methods: `isNoteOn()`, `isNoteOff()`, `getNoteNumber()`, `getVelocity()`

**Key findings:**
- Modern JUCE 8 DSP uses ProcessSpec + AudioBlock pattern (NOT raw pointers)
- All juce::dsp components have `prepare()` and `process()` or `getNextSample()` methods
- `juce::ADSR` is ideal for envelopes (no need for custom implementation)
- Wavetable oscillator requires custom implementation (no juce::dsp::WavetableOscillator class)

---

### Technical Resources

1. **DAFX (Digital Audio Effects) - Chapter on Synthesis**
   - Wavetable synthesis theory and implementation
   - Phase accumulation and wrapping algorithms
   - Frame interpolation techniques (linear, cubic, sinc)
   - Reference for understanding wavetable fundamentals

2. **Designing Audio Effect Plugins in C++ (Will Pirkle)**
   - Synthesizer architecture patterns (oscillator → filter → envelope)
   - Voice management and polyphony implementation
   - Modulation routing strategies (mod matrix design)
   - ADSR envelope implementation details

3. **Surge Synthesizer (Open Source)**
   - GitHub: surge-synthesizer/surge
   - Excellent reference for wavetable implementation code
   - Warp mode algorithms (Sync, FM, AM implementations)
   - Voice management and unison processing
   - Modern C++ patterns for audio DSP

4. **Vital Synthesizer (Open Source)**
   - GitHub: mtytel/vital
   - Very clean wavetable code (frame interpolation, phase accumulation)
   - SIMD-optimized oscillator processing (inspiration for future optimization)
   - Mod matrix implementation (visual routing) - reference for v1.1

5. **Music DSP Archive**
   - musicdsp.org
   - Pink noise filter algorithm (Paul Kellet's method) - used in Codox
   - Constant power panning formula - used for Osc A/B pan
   - Wavetable interpolation comparisons (linear vs. cubic)

---

## Notes

**V1.0 Scope Clarifications:**
- LFOs implemented but NOT routed (no mod matrix in parameter spec)
  - LFO parameters functional (shape, rate, sync)
  - LFO output calculated but not connected to any destinations
  - Future: `/improve` can add mod matrix with routing parameters

- Macros implemented but NOT functional (no mod matrix)
  - Macro parameters exist in APVTS (macro1-4)
  - No routing mechanism (would require mod matrix parameters)
  - Future: `/improve` can add mod matrix (Macro → Filter Cutoff, etc.)

- Effects have fixed internal parameters (only mix exposed)
  - Reduces complexity (8 parameters vs. ~40 for full controls)
  - Fixed parameters tuned to musical defaults
  - Future: `/improve` can expand each effect with full parameter set

- Wavetable format matches Serum (256 × 2048)
  - Enables future wavetable import feature (v1.1+)
  - Large memory footprint (512KB per wavetable) but acceptable
  - 4 built-in wavetables in v1.0 (Basic, Analog, Digital, Vocal)

**Implementation Priority:**
1. Core voice architecture (MIDI, voice allocation, basic sine oscillator)
2. Wavetable engine (frame interpolation, position morphing)
3. Warp modes (one-by-one, test each independently)
4. Additional oscillators (Osc B, Sub, Noise)
5. Filter bank (LP24, LP12, HP24, BP12, Notch)
6. Envelopes (Amp ADSR, Filter ADSR)
7. Unison processing (start with 2, scale to 16 incrementally)
8. Effects chain (add effects one-by-one, test latency)
9. LFOs (generate signals, no routing in v1.0)
10. Polish (CPU optimization, denormal protection, parameter smoothing)

**Critical Success Factors:**
- Incremental implementation (validate each component before moving to next)
- CPU profiling throughout (know when to apply fallback architectures)
- Reference open-source implementations (Surge, Vital for code patterns)
- Test with real musical use cases (not just test tones)

**Known Limitations:**
- No mod matrix (LFOs/Macros generate signals but don't modulate)
- Fixed effect parameters (only mix control)
- No wavetable import (4 built-in wavetables only)
- No tempo sync (LFO sync parameter reserved but inactive)
- No monophonic mode (all notes polyphonic)

**Future Enhancement Opportunities (via /improve):**
- Add mod matrix (LFO → Cutoff, Macro → multiple destinations)
- Expand effect parameters (delay time, reverb size, etc.)
- Add wavetable import/editor
- Implement tempo sync for LFOs and Delay
- Add monophonic mode with legato
- Optimize CPU (SIMD, multithreading, quality settings)
